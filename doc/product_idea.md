# Smart DevSecOps/MLOps Assistant

## Описание проекта

**Smart DevSecOps/MLOps Assistant** - разговорный помощник для автоматизация devops задач через llm model и ui chat-интерфейс с использованием технологий дообучения LLM модели через RAG + CAG.

**Текущий статус:** Основная MLOps инфраструктура (K8s, Kafka, Airflow, MLFlow, KServe, Spark) уже развернута на baremetal.

## Основные функции

### 1. Диагностика и анализ инфраструктуры
- Анализ метрик Prometheus и выявление аномалий
- Обработка логов ELK и поиск причин ошибок  
- Мониторинг состояния Kubernetes кластеров
- Диагностика производительности ML-пайплайнов

### 2. Консультации по troubleshooting
- Анализ проблем на основе runbooks
- Предоставление пошаговых инструкций решения
- Рекомендации по оптимизации инфраструктуры
- Помощь в интерпретации метрик и логов

### 3. Автоматизация DevOps/MLOps задач
- Создание и управление Kubernetes манифестами
- Настройка мониторинга и алертинга
- Оптимизация CI/CD пайплайнов
- Управление MLFlow экспериментами и моделями

### 4. Обучение и документация
- Объяснение best practices для DevOps/MLOps
- Создание кастомной документации
- Обучение команды новым инструментам
- Актуализация runbooks и процедур

## Техническая реализация

### Архитектура
- **Платформа**: Web UI + Chat интерфейс
- **LLM**: Интеграция с большой языковой моделью
- **RAG система**: Векторная база для динамических данных (метрики, логи)
- **CAG система**: База знаний для статической документации
- **Интеграция**: Kubernetes, Prometheus, ELK, Kafka, Airflow, MLFlow, KServe, Spark

### Источники данных
- **Динамические**: Prometheus метрики, ELK логи, Kubernetes API
- **Статические**: Runbooks, документация, troubleshooting guides
- **ML метаданные**: MLFlow эксперименты, модели, артефакты

## Примеры реализации

### RAG: Переобучение/дообновление LLM на новых динамических данных в режиме реального времени

- Ассистент постоянно получает свежие метрики, логи и события из Prometheus/ELK/Kubernetes.
- Каждые несколько секунд данные обрабатываются и добавляются в быстрый поиск.
- Когда вы задаёте вопрос, ассистент находит самые свежие фрагменты и объясняет, что происходит.
- Приоритет свежести: последние минуты/часы важнее старых записей.
- Типичные задержки: ответ 2–3 с; обновление базы 10–30 с.
- Если что‑то сломалось, можно быстро вернуться к предыдущей версии базы.

### CAG: Переобучение/дообновление LLM на новых runbooks и документации раз в неделю

1. Собираем все новые и обновлённые документы в корпоративной wiki/Confluence.
2. Раз в неделю запускается batch job (например, через Airflow), которая:
    - Парсит новые документы,
    - Генерирует эмбеддинги,
    - Обновляет индекс CAG (статическая база знаний),
    - Логирует результаты в MLFlow.
3. После этого LLM-ассистент начинает использовать обновлённую базу.